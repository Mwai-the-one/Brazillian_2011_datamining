{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5630dbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER       6.0   \n",
      "1    536365     71053                  WHITE METAL LANTERN       6.0   \n",
      "2       NaN    84406B       CREAM CUPID HEARTS COAT HANGER       8.0   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE       6.0   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.       6.0   \n",
      "\n",
      "          InvoiceDate  UnitPrice  CustomerID         Country  \n",
      "0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom  \n",
      "1 2010-12-01 08:26:00       3.39     17850.0             NaN  \n",
      "2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom  \n",
      "3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
      "4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
      "\n",
      " Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 547328 entries, 0 to 547327\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   InvoiceNo    536391 non-null  object        \n",
      " 1   StockCode    536376 non-null  object        \n",
      " 2   Description  534937 non-null  object        \n",
      " 3   Quantity     536375 non-null  float64       \n",
      " 4   InvoiceDate  536369 non-null  datetime64[ns]\n",
      " 5   UnitPrice    536384 non-null  float64       \n",
      " 6   CustomerID   402617 non-null  float64       \n",
      " 7   Country      536361 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(3), object(4)\n",
      "memory usage: 33.4+ MB\n",
      "None\n",
      "\n",
      " First 5 Rows:\n",
      "  InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER       6.0   \n",
      "1    536365     71053                  WHITE METAL LANTERN       6.0   \n",
      "2       NaN    84406B       CREAM CUPID HEARTS COAT HANGER       8.0   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE       6.0   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.       6.0   \n",
      "\n",
      "          InvoiceDate  UnitPrice  CustomerID         Country  \n",
      "0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom  \n",
      "1 2010-12-01 08:26:00       3.39     17850.0             NaN  \n",
      "2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom  \n",
      "3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
      "4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
      "\n",
      " Missing Values Count:\n",
      "InvoiceNo       10937\n",
      "StockCode       10952\n",
      "Description     12391\n",
      "Quantity        10953\n",
      "InvoiceDate     10959\n",
      "UnitPrice       10944\n",
      "CustomerID     144711\n",
      "Country         10967\n",
      "dtype: int64\n",
      "\n",
      " Duplicate Rows: 8411\n",
      "\n",
      " Summary Statistics:\n",
      "        InvoiceNo StockCode                         Description  \\\n",
      "count    536391.0    536376                              534937   \n",
      "unique    25780.0      4065                                4217   \n",
      "top      573585.0    85123A  WHITE HANGING HEART T-LIGHT HOLDER   \n",
      "freq       1102.0      2300                                2342   \n",
      "mean          NaN       NaN                                 NaN   \n",
      "min           NaN       NaN                                 NaN   \n",
      "25%           NaN       NaN                                 NaN   \n",
      "50%           NaN       NaN                                 NaN   \n",
      "75%           NaN       NaN                                 NaN   \n",
      "max           NaN       NaN                                 NaN   \n",
      "std           NaN       NaN                                 NaN   \n",
      "\n",
      "             Quantity                    InvoiceDate      UnitPrice  \\\n",
      "count   536375.000000                         536369  536384.000000   \n",
      "unique            NaN                            NaN            NaN   \n",
      "top               NaN                            NaN            NaN   \n",
      "freq              NaN                            NaN            NaN   \n",
      "mean        10.456315  2011-07-04 12:53:19.513432320       5.055011   \n",
      "min     -80995.000000            2010-12-01 00:00:00  -11062.060000   \n",
      "25%          1.000000            2011-03-28 11:34:00       1.250000   \n",
      "50%          3.000000            2011-07-19 17:17:00       2.100000   \n",
      "75%         10.000000            2011-10-19 10:59:00       4.130000   \n",
      "max      80995.000000            2011-12-09 12:50:00   39493.200000   \n",
      "std        222.298340                            NaN     111.099572   \n",
      "\n",
      "           CustomerID         Country  \n",
      "count   402617.000000          536361  \n",
      "unique            NaN              38  \n",
      "top               NaN  United Kingdom  \n",
      "freq              NaN          490439  \n",
      "mean     15287.389387             NaN  \n",
      "min      12346.000000             NaN  \n",
      "25%      13952.000000             NaN  \n",
      "50%      15152.000000             NaN  \n",
      "75%      16791.000000             NaN  \n",
      "max      18287.000000             NaN  \n",
      "std       1713.776500             NaN  \n",
      "\n",
      " Rows with non-positive quantities: 10490\n",
      " Rows with non-positive unit prices: 2499\n",
      "\n",
      " Unique countries:\n",
      " ['United Kingdom' nan 'France' 'Australia' 'Netherlands' 'Germany'\n",
      " 'Norway' 'EIRE' 'Switzerland' 'Spain' 'Poland' 'Portugal' 'Italy'\n",
      " 'Belgium' 'Lithuania' 'Japan' 'Iceland' 'Channel Islands' 'Denmark'\n",
      " 'Cyprus' 'Sweden' 'Austria' 'Israel' 'Finland' 'Bahrain' 'Greece'\n",
      " 'Hong Kong' 'Singapore' 'Lebanon' 'United Arab Emirates' 'Saudi Arabia'\n",
      " 'Czech Republic' 'Canada' 'Unspecified' 'Brazil' 'USA'\n",
      " 'European Community' 'Malta' 'RSA']\n",
      "\n",
      " Summary statistics for numeric columns:\n",
      "             Quantity                    InvoiceDate      UnitPrice  \\\n",
      "count  536375.000000                         536369  536384.000000   \n",
      "mean       10.456315  2011-07-04 12:53:19.513432320       5.055011   \n",
      "min    -80995.000000            2010-12-01 00:00:00  -11062.060000   \n",
      "25%         1.000000            2011-03-28 11:34:00       1.250000   \n",
      "50%         3.000000            2011-07-19 17:17:00       2.100000   \n",
      "75%        10.000000            2011-10-19 10:59:00       4.130000   \n",
      "max     80995.000000            2011-12-09 12:50:00   39493.200000   \n",
      "std       222.298340                            NaN     111.099572   \n",
      "\n",
      "          CustomerID  \n",
      "count  402617.000000  \n",
      "mean    15287.389387  \n",
      "min     12346.000000  \n",
      "25%     13952.000000  \n",
      "50%     15152.000000  \n",
      "75%     16791.000000  \n",
      "max     18287.000000  \n",
      "std      1713.776500  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from scipy import sparse \n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# week 1: member 2\n",
    "\n",
    "data = pd.read_excel(r\"C:\\Users\\USER\\OneDrive\\Documents\\data mining group work\\DataMining_GroupProject_EcomAnalytics\\data\\raw\\sales_and_customer_insights_dirty.xlsx\")\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "\n",
    "# View basic info\n",
    "print(\"\\n Dataset Info:\")\n",
    "print(data.info())\n",
    "\n",
    "print(\"\\n First 5 Rows:\")\n",
    "print(data.head())\n",
    "\n",
    "print(\"\\n Missing Values Count:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "print(\"\\n Duplicate Rows:\", data.duplicated().sum())\n",
    "\n",
    "print(\"\\n Summary Statistics:\")\n",
    "print(data.describe(include='all'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Step 3: Check for negative or zero quantities and prices ---\n",
    "negative_qty = data[data['Quantity'] <= 0]\n",
    "negative_price = data[data['UnitPrice'] <= 0]\n",
    "\n",
    "print(f\"\\n Rows with non-positive quantities: {len(negative_qty)}\")\n",
    "print(f\" Rows with non-positive unit prices: {len(negative_price)}\")\n",
    "\n",
    "# --- Step 4: Check country name inconsistencies ---\n",
    "print(\"\\n Unique countries:\\n\", data['Country'].unique())\n",
    "\n",
    "# --- Step 5: Quick check for outliers using describe() ---\n",
    "print(\"\\n Summary statistics for numeric columns:\\n\", data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6c81c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting ETL Pipeline: Loading C:\\Users\\USER\\OneDrive\\Documents\\data mining group work\\DataMining_GroupProject_EcomAnalytics\\data\\raw\\sales_and_customer_insights_dirty.xlsx ---\n",
      "Initial shape: (547328, 8)\n",
      "Removed 11699 invalid transactions.\n",
      "Final shape: (514256, 8)\n",
      "Duplicates removed: 8065\n",
      "\n",
      "CLEANING COMPLETE. File saved to:\n",
      "C:/Users/USER/OneDrive/Documents/data mining group work/DataMining_GroupProject_EcomAnalytics/data/raw/cleaned_data.csv\n",
      "=== Quantity Outliers ===\n",
      "   InvoiceNo StockCode                        Description  Quantity  \\\n",
      "9     536367     84879      ASSORTED COLOUR BIRD ORNAMENT     320.0   \n",
      "31    536370     10002                                NaN      48.0   \n",
      "44    536370     22492            MINI PAINT SET VINTAGE      360.0   \n",
      "46    536371     22086    PAPER CHAIN KIT 50'S CHRISTMAS       80.0   \n",
      "58    536373     82486  WOOD S/3 CABINET ANT WHITE FINISH      40.0   \n",
      "\n",
      "           InvoiceDate  UnitPrice  CustomerID         Country  IsReturn  \\\n",
      "9  2010-12-01 00:00:00       1.69     13047.0  United Kingdom     False   \n",
      "31 2010-12-01 08:45:00       0.85     12583.0          France     False   \n",
      "44 2010-12-01 08:45:00       0.65     12583.0          France     False   \n",
      "46 2010-12-01 09:00:00       2.55     13748.0  United Kingdom     False   \n",
      "58 2010-12-01 09:02:00       6.95     17850.0  United Kingdom     False   \n",
      "\n",
      "    TotalPrice  Year  Month  Day  \n",
      "9        540.8  2010     12    1  \n",
      "31        40.8  2010     12    1  \n",
      "44       234.0  2010     12    1  \n",
      "46       204.0  2010     12    1  \n",
      "58       278.0  2010     12    1  \n",
      "\n",
      "Quantity Lower Bound: -15.5\n",
      "Quantity Upper Bound: 28.5\n",
      "\n",
      "=== UnitPrice Outliers ===\n",
      "    InvoiceNo StockCode                      Description  Quantity  \\\n",
      "16     536367     22622   BOX OF VINTAGE ALPHABET BLOCKS       2.0   \n",
      "45     536370      POST                          POSTAGE       3.0   \n",
      "65     536374     21258       VICTORIAN SEWING BOX LARGE      32.0   \n",
      "144    536382     21832             CHOCOLATE CALCULATOR      12.0   \n",
      "151    536382     22839  3 TIER CAKE TIN GREEN AND CREAM       2.0   \n",
      "\n",
      "            InvoiceDate  UnitPrice  CustomerID         Country  IsReturn  \\\n",
      "16  2010-12-01 08:34:00       9.95     13047.0  United Kingdom     False   \n",
      "45  2010-12-01 08:45:00      18.00     12583.0          France     False   \n",
      "65  2010-12-01 09:09:00      10.95     15100.0  United Kingdom     False   \n",
      "144 2010-12-01 09:45:00      16.50     16098.0  United Kingdom     False   \n",
      "151 2010-12-01 00:00:00      14.95     16098.0  United Kingdom     False   \n",
      "\n",
      "     TotalPrice  Year  Month  Day  \n",
      "16         19.9  2010     12    1  \n",
      "45         54.0  2010     12    1  \n",
      "65        350.4  2010     12    1  \n",
      "144       198.0  2010     12    1  \n",
      "151        29.9  2010     12    1  \n",
      "\n",
      "UnitPrice Lower Bound: -3.0700000000000003\n",
      "UnitPrice Upper Bound: 8.45\n",
      "\n",
      "Cleaning Completed. DataFrames Created:\n",
      "- df_no_quantity_outliers: removed extreme quantity outliers\n",
      "- df_capped: capped extreme values\n",
      "- df_no_zero_price: removed zero/negative prices\n",
      "\n",
      "--- Starting Monthly One-Hot Encoding for Apriori Analysis ---\n",
      "Max Quantity (Cleaned): 28.0\n",
      "Min Unit Price (Cleaned): 0.001\n",
      "\n",
      "Processing January (Month 1) with 26803 transactions...\n",
      "-> ENCODING COMPLETE for January. Saved 997 transactions to: C:\\Users\\USER\\OneDrive\\Documents\\data mining group work\\DataMining_GroupProject_EcomAnalytics\\data\\raw\\encoded_products_Month_01.csv\n",
      "\n",
      "Processing February (Month 2) with 20833 transactions...\n",
      "-> ENCODING COMPLETE for February. Saved 992 transactions to: C:\\Users\\USER\\OneDrive\\Documents\\data mining group work\\DataMining_GroupProject_EcomAnalytics\\data\\raw\\encoded_products_Month_02.csv\n",
      "\n",
      "Processing March (Month 3) with 27555 transactions...\n",
      "-> ENCODING COMPLETE for March. Saved 1319 transactions to: C:\\Users\\USER\\OneDrive\\Documents\\data mining group work\\DataMining_GroupProject_EcomAnalytics\\data\\raw\\encoded_products_Month_03.csv\n",
      "\n",
      "Processing April (Month 4) with 22671 transactions...\n",
      "-> ENCODING COMPLETE for April. Saved 1128 transactions to: C:\\Users\\USER\\OneDrive\\Documents\\data mining group work\\DataMining_GroupProject_EcomAnalytics\\data\\raw\\encoded_products_Month_04.csv\n",
      "\n",
      "Processing May (Month 5) with 27827 transactions...\n",
      "-> ENCODING COMPLETE for May. Saved 1516 transactions to: C:\\Users\\USER\\OneDrive\\Documents\\data mining group work\\DataMining_GroupProject_EcomAnalytics\\data\\raw\\encoded_products_Month_05.csv\n",
      "\n",
      "Processing June (Month 6) with 27704 transactions...\n",
      "-> ENCODING COMPLETE for June. Saved 1394 transactions to: C:\\Users\\USER\\OneDrive\\Documents\\data mining group work\\DataMining_GroupProject_EcomAnalytics\\data\\raw\\encoded_products_Month_06.csv\n",
      "\n",
      "Processing July (Month 7) with 30372 transactions...\n",
      "-> ENCODING COMPLETE for July. Saved 1335 transactions to: C:\\Users\\USER\\OneDrive\\Documents\\data mining group work\\DataMining_GroupProject_EcomAnalytics\\data\\raw\\encoded_products_Month_07.csv\n",
      "\n",
      "Processing August (Month 8) with 26616 transactions...\n",
      "-> ENCODING COMPLETE for August. Saved 1219 transactions to: C:\\Users\\USER\\OneDrive\\Documents\\data mining group work\\DataMining_GroupProject_EcomAnalytics\\data\\raw\\encoded_products_Month_08.csv\n",
      "\n",
      "Processing September (Month 9) with 38466 transactions...\n",
      "-> ENCODING COMPLETE for September. Saved 1674 transactions to: C:\\Users\\USER\\OneDrive\\Documents\\data mining group work\\DataMining_GroupProject_EcomAnalytics\\data\\raw\\encoded_products_Month_09.csv\n",
      "\n",
      "Processing October (Month 10) with 46432 transactions...\n",
      "-> ENCODING COMPLETE for October. Saved 1846 transactions to: C:\\Users\\USER\\OneDrive\\Documents\\data mining group work\\DataMining_GroupProject_EcomAnalytics\\data\\raw\\encoded_products_Month_10.csv\n",
      "\n",
      "Processing November (Month 11) with 65662 transactions...\n",
      "-> ENCODING COMPLETE for November. Saved 2541 transactions to: C:\\Users\\USER\\OneDrive\\Documents\\data mining group work\\DataMining_GroupProject_EcomAnalytics\\data\\raw\\encoded_products_Month_11.csv\n",
      "\n",
      "Processing December (Month 12) with 50945 transactions...\n",
      "-> ENCODING COMPLETE for December. Saved 2169 transactions to: C:\\Users\\USER\\OneDrive\\Documents\\data mining group work\\DataMining_GroupProject_EcomAnalytics\\data\\raw\\encoded_products_Month_12.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# week 2\n",
    "\n",
    "# member 1\n",
    "# --- WEEK 2: Build ETL Pipeline, Handle Missing Data (Member 1 Task) ---\n",
    "\n",
    "def build_etl_pipeline(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads data, cleans column names, converts types, and handles missing values.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\n--- Starting ETL Pipeline: Loading {file_path} ---\")\n",
    "\n",
    "    # 1. Extract\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: file not found: {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Clean column names\n",
    "    df.columns = df.columns.str.strip()\n",
    "    print(f\"Initial shape: {df.shape}\")\n",
    "\n",
    "    # Convert types\n",
    "    df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], errors='coerce')\n",
    "\n",
    "    # Remove invalid rows\n",
    "    invalid_count = df[(df['Quantity'] <= 0) | (df['UnitPrice'] <= 0)].shape[0]\n",
    "    df = df[(df['Quantity'] > 0) & (df['UnitPrice'] > 0)]\n",
    "\n",
    "    print(f\"Removed {invalid_count} invalid transactions.\")\n",
    "    print(f\"Final shape: {df.shape}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "df = build_etl_pipeline(r\"C:\\Users\\USER\\OneDrive\\Documents\\data mining group work\\DataMining_GroupProject_EcomAnalytics\\data\\raw\\sales_and_customer_insights_dirty.xlsx\")\n",
    "if df is None or not isinstance(df, pd.DataFrame):\n",
    "    raise RuntimeError(\"ETL pipeline failed to produce DataFrame — check earlier errors/logs\")\n",
    "\n",
    "\n",
    "# member 2\n",
    "\n",
    "data= df.copy()\n",
    "# 1. Remove Duplicate Records\n",
    "\n",
    "duplicates_before = df.duplicated().sum()\n",
    "data = data.drop_duplicates()\n",
    "duplicates_after = data.duplicated().sum()\n",
    "\n",
    "print(f\"Duplicates removed: {duplicates_before - duplicates_after}\")\n",
    "\n",
    "\n",
    "# 2. Handle Missing Values\n",
    "\n",
    "\n",
    "# a) Fill missing Description with \"Unknown Product\"\n",
    "data['Description'] = data['Description'].dropna()\n",
    "\n",
    "# b) Country missing → Fill as \"Unknown\"\n",
    "data['Country'] = data['Country'].fillna(\"Unknown\")\n",
    "\n",
    "# c) InvoiceDate missing → Remove (these are unusable)\n",
    "data = data.dropna(subset=['InvoiceDate'])\n",
    "\n",
    "# d) StockCode & InvoiceNo (critical identifiers) → remove missing\n",
    "data = data.dropna(subset=['InvoiceNo', 'StockCode'])\n",
    "\n",
    "# e) CustomerID → Keep but mark missing as -1 for analysis\n",
    "data['CustomerID'] = data['CustomerID'].fillna(-1)\n",
    "\n",
    "\n",
    "# 3. Fix Invalid Negative Values\n",
    "\n",
    "# Negative quantity means returns → keep but tag\n",
    "data['IsReturn'] = data['Quantity'] < 0\n",
    "\n",
    "\n",
    "\n",
    "# 4. Standardize Country Names\n",
    "\n",
    "country_replacements = {\n",
    "    \"RSA\": \"South Africa\",\n",
    "    \"EIRE\": \"Ireland\",\n",
    "    \"European Community\": \"Europe\",\n",
    "    \"Unspecified\": \"Unknown\"\n",
    "}\n",
    "data['Country'] = data['Country'].replace(country_replacements)\n",
    "\n",
    "\n",
    "# 5. Create Calculated Fields (For Week 4 Mining)\n",
    "\n",
    "\n",
    "# Total price per transaction\n",
    "data['TotalPrice'] = data['Quantity'] * data['UnitPrice']\n",
    "\n",
    "# Extract date components\n",
    "data['Year'] = data['InvoiceDate'].dt.year\n",
    "data['Month'] = data['InvoiceDate'].dt.month\n",
    "data['Day'] = data['InvoiceDate'].dt.day\n",
    "\n",
    "\n",
    "# 6. Save Cleaned Dataset\n",
    "\n",
    "cleaned_path = \"C:/Users/USER/OneDrive/Documents/data mining group work/DataMining_GroupProject_EcomAnalytics/data/raw/cleaned_data.csv\"\n",
    "data.to_csv(cleaned_path, index=False)\n",
    "print(\"\\nCLEANING COMPLETE. File saved to:\")\n",
    "print(cleaned_path)\n",
    "\n",
    "\n",
    "#member 3\n",
    "\n",
    "# 1. Detect Outliers Using IQR\n",
    "def detect_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Detect outliers in Quantity\n",
    "quantity_outliers, q_low, q_high = detect_outliers_iqr(data, 'Quantity')\n",
    "\n",
    "# Detect outliers in UnitPrice\n",
    "price_outliers, p_low, p_high = detect_outliers_iqr(data, 'UnitPrice')\n",
    "\n",
    "print(\"=== Quantity Outliers ===\")\n",
    "print(quantity_outliers.head())\n",
    "print(\"\\nQuantity Lower Bound:\", q_low)\n",
    "print(\"Quantity Upper Bound:\", q_high)\n",
    "\n",
    "print(\"\\n=== UnitPrice Outliers ===\")\n",
    "print(price_outliers.head())\n",
    "print(\"\\nUnitPrice Lower Bound:\", p_low)\n",
    "print(\"UnitPrice Upper Bound:\", p_high)\n",
    "\n",
    "# 2. Suggested Handling Strategies (code-ready)\n",
    "\n",
    "\n",
    "# Remove negative quantities (invalid)\n",
    "df_clean = data[data['Quantity'] >= 0]\n",
    "\n",
    "# Option 1: Remove extremely high outliers\n",
    "df_clean = df_clean[(df_clean['Quantity'] <= q_high)]\n",
    "df_clean = df_clean[(df_clean['UnitPrice'] <= p_high)]\n",
    "\n",
    "# Option 2: Cap values (Winsorization)\n",
    "df_capped = df_clean.copy()\n",
    "df_capped['Quantity'] = df_capped['Quantity'].clip(lower=q_low, upper=q_high)\n",
    "df_capped['UnitPrice'] = df_capped['UnitPrice'].clip(lower=p_low, upper=p_high)\n",
    "\n",
    "# Remove zero or negative prices\n",
    "df_no_zero_price = data[data['UnitPrice'] > 0]\n",
    "\n",
    "print(\"\\nCleaning Completed. DataFrames Created:\")\n",
    "print(\"- df_no_quantity_outliers: removed extreme quantity outliers\")\n",
    "print(\"- df_capped: capped extreme values\")\n",
    "print(\"- df_no_zero_price: removed zero/negative prices\")\n",
    "\n",
    "\n",
    "# member 4\n",
    "# --- Week 2: Preparation of data for mining (Scaling & Monthly Encoding) ---\n",
    "\n",
    "def encode_monthly_transactions(df_input: pd.DataFrame, base_path: str):\n",
    "    \"\"\"\n",
    "    Scales features, then splits the data by month, performs one-hot encoding\n",
    "    for each month, and saves the encoded sparse matrix to separate CSV files.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Starting Monthly One-Hot Encoding for Apriori Analysis ---\")\n",
    "    \n",
    "    # 1. Scaling (Performed once on the clean, full data)\n",
    "    df_scaled = df_input.copy()\n",
    "\n",
    "    scaler_Q = MinMaxScaler()\n",
    "    scaler_UP = MinMaxScaler()\n",
    "    df_scaled['scaled_Q'] = scaler_Q.fit_transform(df_scaled[['Quantity']])\n",
    "    df_scaled['scaled_UP'] = scaler_UP.fit_transform(df_scaled[['UnitPrice']])\n",
    "    \n",
    "    print(f'Max Quantity (Cleaned): {df_scaled[\"Quantity\"].max()}')\n",
    "    print(f'Min Unit Price (Cleaned): {df_scaled[\"UnitPrice\"].min()}')\n",
    "\n",
    "    # 2. Iterate through each month and encode separately\n",
    "    months = sorted(df_scaled['Month'].unique())\n",
    "    \n",
    "    for month_num in months:\n",
    "        month_data = df_scaled[df_scaled['Month'] == month_num].copy()\n",
    "        month_name = datetime(2023, month_num, 1).strftime('%B')\n",
    "        \n",
    "        print(f\"\\nProcessing {month_name} (Month {month_num}) with {month_data.shape[0]} transactions...\")\n",
    "        \n",
    "        # Build transactions: list of lists (one transaction per invoice)\n",
    "        transactions = month_data.groupby('InvoiceNo')['Description'] \\\n",
    "                                .apply(lambda items: items.dropna().astype(str).unique().tolist()) \\\n",
    "                                .tolist()\n",
    "\n",
    "        if not transactions:\n",
    "            print(f\"Skipping {month_name}: No transactions found after grouping.\")\n",
    "            continue\n",
    "            \n",
    "        te = TransactionEncoder()\n",
    "        te_data = te.fit(transactions).transform(transactions)\n",
    "\n",
    "        # Convert safely and keep memory-efficient path for sparse matrices\n",
    "        if sparse.issparse(te_data):\n",
    "            # Option A: keep sparse and build a sparse-aware DataFrame\n",
    "            encoded_products = pd.DataFrame.sparse.from_spmatrix(te_data, columns=list(te.columns_))\n",
    "        else:\n",
    "            te_array = np.asarray(te_data)\n",
    "            encoded_products = pd.DataFrame(te_array, columns=list(te.columns_))\n",
    "\n",
    "        # Ensure ints\n",
    "        encoded_products = encoded_products.astype(int)\n",
    "\n",
    "        # Save encoded_products\n",
    "        # File name now includes the month for clarity\n",
    "        encoded_products_path = f\"{base_path}\\\\encoded_products_Month_{month_num:02d}.csv\"\n",
    "        encoded_products.to_csv(encoded_products_path, index=True)\n",
    "        print(f\"-> ENCODING COMPLETE for {month_name}. Saved {encoded_products.shape[0]} transactions to: {encoded_products_path}\")\n",
    "\n",
    "# Execute the monthly encoding\n",
    "base_path = r\"C:\\Users\\USER\\OneDrive\\Documents\\data mining group work\\DataMining_GroupProject_EcomAnalytics\\data\\raw\"\n",
    "encode_monthly_transactions(df_clean, base_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
